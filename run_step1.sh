#!/bin/bash
set -euo pipefail

# --- 1. é…ç½®åŒºåŸŸ (è¯·ä¿®æ”¹è¿™é‡Œ) ---
INPUT_JSONL="/hpc2hdd/home/ycui785/dataset/llava-665k/llava_v1_5_mix665k_shuffled_fixed.jsonl"
IMAGE_ROOT="/hpc2hdd/home/ycui785/dataset/llava-665k/train_split"
MODEL_PATH="/hpc2hdd/home/ycui785/model/qwen2_5_vl_3b"

OUTPUT_NPY="feature_665/llava_final_embeddings.npy"
OUTPUT_JSONL="feature_665/llava_final_valid.jsonl"

# å¹¶è¡Œé…ç½®
NUM_GPUS=1
BATCH_SIZE=2
CHUNK_SIZE=10000

# âœ… æ–°å¢ï¼šDataLoader / AMP é…ç½®ï¼ˆå»ºè®®ï¼‰
NUM_WORKERS=1          # æ¯è¿›ç¨‹ workersï¼›2å¡ä¸€èˆ¬ 4~8 éƒ½è¡Œ
PREFETCH_FACTOR=4      # é¢„å–å€æ•°ï¼ˆworkers>0 æ‰ç”Ÿæ•ˆï¼‰
AMP_DTYPE="fp16"       # none|fp16|bf16ï¼ˆå»ºè®® fp16ï¼›A100/H100 å¯ bf16ï¼‰

# æ—¥å¿—ç›®å½•
LOG_DIR="logs_stage1_665"
mkdir -p "$LOG_DIR"
mkdir -p "$(dirname "$OUTPUT_NPY")"

echo "========================================================"
echo "ğŸš€ Start Stage 1: Multimodal Feature Extraction"
echo "   Input:  $INPUT_JSONL"
echo "   GPUs:   $NUM_GPUS"
echo "   BS:     $BATCH_SIZE"
echo "   Chunk:  $CHUNK_SIZE"
echo "   Workers per GPU: $NUM_WORKERS"
echo "   Prefetch: $PREFETCH_FACTOR"
echo "   AMP: $AMP_DTYPE"
echo "========================================================"

# --- 2. å¹¶è¡Œå¯åŠ¨æå–ä»»åŠ¡ (Extraction) ---
pids=()

for (( i=0; i<NUM_GPUS; i++ )); do
  echo "[Master] Launching Worker $i on GPU $i..."

  CUDA_VISIBLE_DEVICES=$i python -u stage1_transformers_checkpoint_dp.py \
    --input_jsonl "$INPUT_JSONL" \
    --image_root "$IMAGE_ROOT" \
    --output_npy "$OUTPUT_NPY" \
    --output_jsonl "$OUTPUT_JSONL" \
    --qwen_model_path "$MODEL_PATH" \
    --batch_size "$BATCH_SIZE" \
    --chunk_size_samples "$CHUNK_SIZE" \
    --chunk_offset "$i" \
    --chunk_stride "$NUM_GPUS" \
    --encoder_type "qwen2vl" \
    --num_workers "$NUM_WORKERS" \
    --prefetch_factor "$PREFETCH_FACTOR" \
    --amp_dtype "$AMP_DTYPE" \
    > "$LOG_DIR/worker_${i}.log" 2>&1 &

  pids+=($!)
done

# --- 3. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ (Wait) ---
echo "--------------------------------------------------------"
echo "â³ All $NUM_GPUS workers launched. Waiting for completion..."
echo "   Check logs in: $LOG_DIR/worker_*.log"

fail=0
for pid in "${pids[@]}"; do
  if ! wait "$pid"; then
    fail=1
  fi
done

if [[ "$fail" -ne 0 ]]; then
  echo "âŒ One or more workers failed. Please check logs in $LOG_DIR."
  exit 1
fi

echo "âœ… All extraction workers finished!"

# --- 4. æ‰§è¡Œåˆå¹¶ (Merge) ---
echo "--------------------------------------------------------"
echo "ğŸ”„ Starting Merge process..."

python -u stage1_transformers_checkpoint_dp.py \
  --input_jsonl "$INPUT_JSONL" \
  --output_npy "$OUTPUT_NPY" \
  --output_jsonl "$OUTPUT_JSONL" \
  --qwen_model_path "$MODEL_PATH" \
  --chunk_size_samples "$CHUNK_SIZE" \
  --merge_only

echo "========================================================"
echo "ğŸ‰ Stage 1 Complete!"
echo "   Embeddings saved to: $OUTPUT_NPY"
echo "========================================================"
